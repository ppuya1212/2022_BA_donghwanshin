# Python Tutorial by 2021010668 신동환

## 1. Dimensionality Reduction
<details>
    <summary> View Contents </summary>

  * 차원축소의 목적: 불필요한 데이터를 제거하여 복잡도를 낮추면서 성능을 유지, computation power 절감

  * 차원축소 기법의 종류
  ![image](https://user-images.githubusercontent.com/77199749/195138151-b06862d6-5887-42c5-b660-7b9d6816f127.png)

  * Genetic Algorithm
  ![image](https://user-images.githubusercontent.com/77199749/195138246-bb82f29a-2246-4db7-a469-3672852b8b72.png)

  * PCA vs. MDS
  ![image](https://user-images.githubusercontent.com/77199749/195138319-51de7065-8de3-4616-9dbb-e8a9b7548cc9.png)

</details>

## 2. SVM&SVR
<details>
    <summary> View Contents </summary>
    
  * Support Vector Machine(SVM): 마진을 극대화하는 초평면활용 분류기
  ![image](https://user-images.githubusercontent.com/77199749/195419556-907a0536-c7e5-4352-aecd-09477dc94630.png)

  * SVM 4 Cases
  ![image](https://user-images.githubusercontent.com/77199749/195419669-c1fcbe7a-acff-405e-923c-e78a1c3cc051.png)

  * SVM Case1: Linear&Hard Margin
  ![image](https://user-images.githubusercontent.com/77199749/195419851-e0627d18-2c57-452e-9665-a03dd14653a9.png)

  * Support Vector Regression: "𝝐-tube"를 가진 회귀 추정식
  ![image](https://user-images.githubusercontent.com/77199749/195420076-533c14b2-9dbb-4476-a847-50e36ca8ff15.png)

</details>
    
==========================================================================
## Reference
- https://sustaining-starflower-aff.notion.site/2022-2-0e068bff3023401fa9fa13e96c0269d7 (강필성 교수님 ba수업자료)
